{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch version:  1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "print(\"torch version: \", torch.__version__)\n",
    "\n",
    "#from helpers import visualize\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham_data\\splitted_ham10000_v2\n",
      "ham_data\\splitted_ham10000_v2\\train\n"
     ]
    }
   ],
   "source": [
    "# Setup path to data folder\n",
    "data_path = Path(\"ham_data/\")\n",
    "# image_path = data_path / \"splitted_ham10000\"\n",
    "\n",
    "ham1000v2_aug = data_path / \"splitted_ham10000_v2\"\n",
    "\n",
    "train_dir = ham1000v2_aug / \"train\"\n",
    "# test_dir = image_path / \"test\"\n",
    "\n",
    "# file_labels = []\n",
    "# for name in os.listdir(train_dir):\n",
    "#     file_labels.append(name)\n",
    "\n",
    "# print(\"Train directory: \",train_dir)\n",
    "# print(\"Test directory: \",test_dir)\n",
    "# print(\"Labels: \",file_labels)\n",
    "\n",
    "print(ham1000v2_aug)\n",
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is ACA4-631C\n",
      "\n",
      " Directory of c:\\Users\\unatt\\OneDrive\\Masa�st�\\ham10000_skin\\ham_data\\splitted_ham10000_v2\\train\n",
      "\n",
      "03.03.2023  18:00    <DIR>          .\n",
      "03.03.2023  17:59    <DIR>          ..\n",
      "03.03.2023  17:59    <DIR>          akiec\n",
      "03.03.2023  17:59    <DIR>          bcc\n",
      "03.03.2023  17:59    <DIR>          bkl\n",
      "03.03.2023  17:59    <DIR>          df\n",
      "03.03.2023  17:59    <DIR>          mel\n",
      "03.03.2023  18:00    <DIR>          nv\n",
      "03.03.2023  18:00    <DIR>          vasc\n",
      "               0 File(s)              0 bytes\n",
      "               9 Dir(s)  63.002.898.432 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir ham_data\\splitted_ham10000_v2\\train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 74.74 (s).\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform_rotate45 = transforms.Compose( [transforms.RandomRotation(45), transforms.ToTensor()] )\n",
    "transform_rotate90 = transforms.Compose( [transforms.RandomRotation(90), transforms.ToTensor()] )\n",
    "transform_rotate180 = transforms.Compose( [transforms.RandomRotation(180), transforms.ToTensor()] )\n",
    "transform_rotate270 = transforms.Compose( [transforms.RandomRotation(270), transforms.ToTensor()] )\n",
    "transform_h_flip = transforms.Compose( [transforms.RandomHorizontalFlip(p=1), transforms.ToTensor()] )\n",
    "transform_v_flip = transforms.Compose( [transforms.RandomVerticalFlip(p=1), transforms.ToTensor()] )\n",
    "transform_random_rsize = transforms.Compose( [transforms.RandomResizedCrop(size=(224, 224), scale=(0.32, 0.72), ratio=(0.72, 1)), \n",
    "                                            transforms.ToTensor()] )\n",
    "\n",
    "\n",
    "df_path_train = train_dir/ \"vasc\"\n",
    "\n",
    "start_aug_time = time.time()\n",
    "for file in os.listdir(df_path_train):\n",
    "    \n",
    "    if file.endswith(\".jpg\"):\n",
    "        # print(\"----> IMG: \", file)\n",
    "        img_name = os.path.basename(file).partition(\".jpg\")[0] # remove .jpg extension\n",
    "    if file.endswith(\".png\"):\n",
    "        # print(\"----> IMG: \", file)\n",
    "        img_name = os.path.basename(file).partition(\".png\")[0] # remove .png extension\n",
    "    \n",
    "    if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "            \n",
    "        img_path = df_path_train/file\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        h_img = transform_h_flip(img)\n",
    "        v_img = transform_v_flip(img)\n",
    "        # rotate45_img = transform_rotate45(img)\n",
    "        rotate90_img = transform_rotate90(img)\n",
    "        rotate270_img = transform_rotate270(img)\n",
    "        rand_rsize_img = transform_random_rsize(img)\n",
    "        rand_rsize2_img = transform_random_rsize(img)\n",
    "\n",
    "        desired_extension = \".png\"\n",
    "        save_to = \"new_augmented/\" # df_path_train\n",
    "\n",
    "        transforms.ToPILImage()(h_img).save(save_to+img_name+\"_h_flip\"+desired_extension)\n",
    "        transforms.ToPILImage()(v_img).save(save_to+img_name+\"_v_flip\"+desired_extension)\n",
    "        # transforms.ToPILImage()(rotate45_img).save(save_to+img_name+\"_rot45_\"+desired_extension)\n",
    "        transforms.ToPILImage()(rotate90_img).save(save_to+img_name+\"_rot90_\"+desired_extension)\n",
    "        transforms.ToPILImage()(rotate270_img).save(save_to+img_name+\"_rot270_\"+desired_extension)\n",
    "        transforms.ToPILImage()(rand_rsize_img).save(save_to+img_name+\"_r_size_\"+desired_extension)\n",
    "        transforms.ToPILImage()(rand_rsize2_img).save(save_to+img_name+\"_r_size_2_\"+desired_extension)\n",
    "    \n",
    "    # rotations to flipped images are also applicable\n",
    "\n",
    "end_aug_time = time.time()\n",
    "\n",
    "print(f\"Total training time: {end_aug_time-start_aug_time:.2f} (s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_dataload import create_dataloader, get_class_names_dloader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(), # between 0 & 1 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                         std=[0.229, 0.224, 0.225]) # standard deviation of [0.229, 0.224, 0.225] (across each colour channel)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  transform_random_rsize = transforms.Compose( [transforms.RandomResizedCrop(\n",
    "                                              size=(224, 224), \n",
    "                                              scale=(0.32, 0.72), \n",
    "                                              ratio=(0.72, 1)), \n",
    "                                            transforms.ToTensor()] )\n",
    "\n",
    "  img = Image.open(denemee_aug_path/\"indir.jpg\")\n",
    "  rand_rsize_img = transform_random_rsize(img)\n",
    "  transforms.ToPILImage()(rand_rsize_img).save(\"new_augmented/\"+\"indir\"+\"_r_size_\"+str(i)+\"_.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env_v_1_13_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ef3a9cac980403b72596997137697ffb9b7d327cc62ec10439bb6097f59ed3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
